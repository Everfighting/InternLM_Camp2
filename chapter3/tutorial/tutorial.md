# 实验环境配置步骤

    1、选择创建开发机
    2、勾选镜像Cuda11.7-conda
    3、选择匹配的资源如：30% A100 * 1
    4、进入开发机
    5、创建环境：studio-conda -o internlm-base -t InternLM2_Huixiangdou
    6、激活环境：conda activate InternLM2_Huixiangdou
    7、补充确实的安装包

![1](./src/1.png)

# 下载对应的Embedding模型和大模型参数
![2](./src/2.png)

# 下载安装茴香豆所需要的依赖
![3](./src/3.png)

# 下载茴香豆对应的代码切换到对应的版本
![4](./src/4.png)

# 修改代码对应的调用的模型的路径，改成本地的
![5](./src/5.png)
修改后的路径如下：
![6](./src/6.png)

# 增加问题接受列表和增加问题拒绝列表
![7](./src/7.png)

# 将相关内容入向量数据库
![8](./src/8.png)
![9](./src/9.png)
入库时候发生了报错，超过了最大的长度
![10](./src/10.png)
修改对应的参数最大长度，重新入库
![11](./src/11.png)
成功入库
![12](./src/12.png)

# 测试茴香豆效果
在queries中增加我们需要测试的相关问题，加载相关模型
![13](./src/13.png)
![14](./src/14.png)
问题如果符合要求则无法回答
![15](./src/15.png)
![16](./src/16.png)

从good_question中挑选较好的问题可以正确的回答
![17](./src/17.png)
![18](./src/18.png)
![19](./src/19.png)
![20](./src/20.png)
![21](./src/21.png)

# 注册 Serper提供搜索功能
![22](./src/22.png)
# 修改对应配置文件
![23](./src/23.png)


# 使用远程模型
```
enable_local = 0 # 关闭本地模型
enable_remote = 1 # 启用云端模型
```
根据相应的模型的配置和参数进行配置文件的配置，由于没有远程的API这部分暂时没有实验

# 在线部署版界面
![24](./src/24.png)
可以上传文件进行尝试，具体可以见作业中的相关尝试中截图


# 本地服务器使用Gradio进行相关测试
![25](./src/25.png)
![26](./src/26.png)
